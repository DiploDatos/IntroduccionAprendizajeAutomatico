{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Selección de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Definimos datos de lenguaje natural de juguete y vectorizamos el input usando bolsas de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "    ('chinese beijing chinese', 'zh'),\n",
    "    ('chinese chinese shangai', 'zh'),\n",
    "    ('chinese macao', 'zh'),\n",
    "    ('chinese beijing tokyo', 'zh'),\n",
    "    ('chinese beijing osaka', 'zh'),\n",
    "    ('tokyo japan chinese', 'ja'),\n",
    "    ('tokyo japan osaka', 'ja'),\n",
    "    ('osaka', 'ja'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_docs = np.array([doc for doc, _ in training])\n",
    "y = np.array([cls for _, cls in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(X_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada\n",
    "\n",
    "- [Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División K-Fold\n",
    "\n",
    "Podemos usar [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) para hacer cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 3 4 5 7] VAL: [2 6] ['zh' 'ja']\n",
      "TRAIN: [0 2 3 4 5 6] VAL: [1 7] ['zh' 'ja']\n",
      "TRAIN: [1 2 4 5 6 7] VAL: [0 3] ['zh' 'zh']\n",
      "TRAIN: [0 1 2 3 6 7] VAL: [4 5] ['zh' 'ja']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    print(f\"TRAIN: {train_index} VAL: {val_index} {y_val}\")\n",
    "\n",
    "    #model.fit(X_train, y_train)\n",
    "    #model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División K-Fold Estratificada\n",
    "\n",
    "Para que la división sea estratificada, usamos [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 3 6 7] VAL: [2 4 5] ['zh' 'zh' 'ja']\n",
      "TRAIN: [1 2 4 5 7] VAL: [0 3 6] ['zh' 'zh' 'ja']\n",
      "TRAIN: [0 2 3 4 5 6] VAL: [1 7] ['zh' 'ja']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=2)\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    print(f\"TRAIN: {train_index} VAL: {val_index} {y_val}\")\n",
    "\n",
    "    #model.fit(X_train, y_train)\n",
    "    #model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda en Grilla (Grid Search)\n",
    "\n",
    "- [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla de Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A decision tree classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <tree>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    criterion : {\"gini\", \"entropy\"}, default=\"gini\"\u001b[0m\n",
       "\u001b[0;34m        The function to measure the quality of a split. Supported criteria are\u001b[0m\n",
       "\u001b[0;34m        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    splitter : {\"best\", \"random\"}, default=\"best\"\u001b[0m\n",
       "\u001b[0;34m        The strategy used to choose the split at each node. Supported\u001b[0m\n",
       "\u001b[0;34m        strategies are \"best\" to choose the best split and \"random\" to choose\u001b[0m\n",
       "\u001b[0;34m        the best random split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_depth : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The maximum depth of the tree. If None, then nodes are expanded until\u001b[0m\n",
       "\u001b[0;34m        all leaves are pure or until all leaves contain less than\u001b[0m\n",
       "\u001b[0;34m        min_samples_split samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_split : int or float, default=2\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to split an internal node:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_split` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_split` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_split * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_leaf : int or float, default=1\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to be at a leaf node.\u001b[0m\n",
       "\u001b[0;34m        A split point at any depth will only be considered if it leaves at\u001b[0m\n",
       "\u001b[0;34m        least ``min_samples_leaf`` training samples in each of the left and\u001b[0m\n",
       "\u001b[0;34m        right branches.  This may have the effect of smoothing the model,\u001b[0m\n",
       "\u001b[0;34m        especially in regression.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_leaf` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_leaf` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_leaf * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_weight_fraction_leaf : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        The minimum weighted fraction of the sum total of weights (of all\u001b[0m\n",
       "\u001b[0;34m        the input samples) required to be at a leaf node. Samples have\u001b[0m\n",
       "\u001b[0;34m        equal weight when sample_weight is not provided.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of features to consider when looking for the best split:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            - If int, then consider `max_features` features at each split.\u001b[0m\n",
       "\u001b[0;34m            - If float, then `max_features` is a fraction and\u001b[0m\n",
       "\u001b[0;34m              `int(max_features * n_features)` features are considered at each\u001b[0m\n",
       "\u001b[0;34m              split.\u001b[0m\n",
       "\u001b[0;34m            - If \"auto\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If \"sqrt\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If \"log2\", then `max_features=log2(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If None, then `max_features=n_features`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note: the search for a split does not stop until at least one\u001b[0m\n",
       "\u001b[0;34m        valid partition of the node samples is found, even if it requires to\u001b[0m\n",
       "\u001b[0;34m        effectively inspect more than ``max_features`` features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int, RandomState instance or None, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls the randomness of the estimator. The features are always\u001b[0m\n",
       "\u001b[0;34m        randomly permuted at each split, even if ``splitter`` is set to\u001b[0m\n",
       "\u001b[0;34m        ``\"best\"``. When ``max_features < n_features``, the algorithm will\u001b[0m\n",
       "\u001b[0;34m        select ``max_features`` at random at each split before finding the best\u001b[0m\n",
       "\u001b[0;34m        split among them. But the best found split may vary across different\u001b[0m\n",
       "\u001b[0;34m        runs, even if ``max_features=n_features``. That is the case, if the\u001b[0m\n",
       "\u001b[0;34m        improvement of the criterion is identical for several splits and one\u001b[0m\n",
       "\u001b[0;34m        split has to be selected at random. To obtain a deterministic behaviour\u001b[0m\n",
       "\u001b[0;34m        during fitting, ``random_state`` has to be fixed to an integer.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_leaf_nodes : int, default=None\u001b[0m\n",
       "\u001b[0;34m        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\u001b[0m\n",
       "\u001b[0;34m        Best nodes are defined as relative reduction in impurity.\u001b[0m\n",
       "\u001b[0;34m        If None then unlimited number of leaf nodes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_impurity_decrease : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        A node will be split if this split induces a decrease of the impurity\u001b[0m\n",
       "\u001b[0;34m        greater than or equal to this value.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The weighted impurity decrease equation is the following::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            N_t / N * (impurity - N_t_R / N_t * right_impurity\u001b[0m\n",
       "\u001b[0;34m                                - N_t_L / N_t * left_impurity)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        where ``N`` is the total number of samples, ``N_t`` is the number of\u001b[0m\n",
       "\u001b[0;34m        samples at the current node, ``N_t_L`` is the number of samples in the\u001b[0m\n",
       "\u001b[0;34m        left child, and ``N_t_R`` is the number of samples in the right child.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\u001b[0m\n",
       "\u001b[0;34m        if ``sample_weight`` is passed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_impurity_split : float, default=0\u001b[0m\n",
       "\u001b[0;34m        Threshold for early stopping in tree growth. A node will split\u001b[0m\n",
       "\u001b[0;34m        if its impurity is above the threshold, otherwise it is a leaf.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. deprecated:: 0.19\u001b[0m\n",
       "\u001b[0;34m           ``min_impurity_split`` has been deprecated in favor of\u001b[0m\n",
       "\u001b[0;34m           ``min_impurity_decrease`` in 0.19. The default value of\u001b[0m\n",
       "\u001b[0;34m           ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\u001b[0m\n",
       "\u001b[0;34m           will be removed in 1.0 (renaming of 0.25).\u001b[0m\n",
       "\u001b[0;34m           Use ``min_impurity_decrease`` instead.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    class_weight : dict, list of dict or \"balanced\", default=None\u001b[0m\n",
       "\u001b[0;34m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[0m\n",
       "\u001b[0;34m        If None, all classes are supposed to have weight one. For\u001b[0m\n",
       "\u001b[0;34m        multi-output problems, a list of dicts can be provided in the same\u001b[0m\n",
       "\u001b[0;34m        order as the columns of y.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that for multioutput (including multilabel) weights should be\u001b[0m\n",
       "\u001b[0;34m        defined for each class of every column in its own dict. For example,\u001b[0m\n",
       "\u001b[0;34m        for four-class multilabel classification weights should be\u001b[0m\n",
       "\u001b[0;34m        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\u001b[0m\n",
       "\u001b[0;34m        [{1:1}, {2:5}, {3:1}, {4:1}].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
       "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
       "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        For multi-output, the weights of each column of y will be multiplied.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that these weights will be multiplied with sample_weight (passed\u001b[0m\n",
       "\u001b[0;34m        through the fit method) if sample_weight is specified.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ccp_alpha : non-negative float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        Complexity parameter used for Minimal Cost-Complexity Pruning. The\u001b[0m\n",
       "\u001b[0;34m        subtree with the largest cost complexity that is smaller than\u001b[0m\n",
       "\u001b[0;34m        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\u001b[0m\n",
       "\u001b[0;34m        :ref:`minimal_cost_complexity_pruning` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    classes_ : ndarray of shape (n_classes,) or list of ndarray\u001b[0m\n",
       "\u001b[0;34m        The classes labels (single output problem),\u001b[0m\n",
       "\u001b[0;34m        or a list of arrays of class labels (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_importances_ : ndarray of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        The impurity-based feature importances.\u001b[0m\n",
       "\u001b[0;34m        The higher, the more important the feature.\u001b[0m\n",
       "\u001b[0;34m        The importance of a feature is computed as the (normalized)\u001b[0m\n",
       "\u001b[0;34m        total reduction of the criterion brought by that feature.  It is also\u001b[0m\n",
       "\u001b[0;34m        known as the Gini importance [4]_.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Warning: impurity-based feature importances can be misleading for\u001b[0m\n",
       "\u001b[0;34m        high cardinality features (many unique values). See\u001b[0m\n",
       "\u001b[0;34m        :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features_ : int\u001b[0m\n",
       "\u001b[0;34m        The inferred value of max_features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_classes_ : int or list of int\u001b[0m\n",
       "\u001b[0;34m        The number of classes (for single output problems),\u001b[0m\n",
       "\u001b[0;34m        or a list containing the number of classes for each\u001b[0m\n",
       "\u001b[0;34m        output (for multi-output problems).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_features_ : int\u001b[0m\n",
       "\u001b[0;34m        The number of features when ``fit`` is performed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_outputs_ : int\u001b[0m\n",
       "\u001b[0;34m        The number of outputs when ``fit`` is performed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    tree_ : Tree instance\u001b[0m\n",
       "\u001b[0;34m        The underlying Tree object. Please refer to\u001b[0m\n",
       "\u001b[0;34m        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\u001b[0m\n",
       "\u001b[0;34m        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\u001b[0m\n",
       "\u001b[0;34m        for basic usage of these attributes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    DecisionTreeRegressor : A decision tree regressor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    The default values for the parameters controlling the size of the trees\u001b[0m\n",
       "\u001b[0;34m    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\u001b[0m\n",
       "\u001b[0;34m    unpruned trees which can potentially be very large on some data sets. To\u001b[0m\n",
       "\u001b[0;34m    reduce memory consumption, the complexity and size of the trees should be\u001b[0m\n",
       "\u001b[0;34m    controlled by setting those parameter values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The :meth:`predict` method operates using the :func:`numpy.argmax`\u001b[0m\n",
       "\u001b[0;34m    function on the outputs of :meth:`predict_proba`. This means that in\u001b[0m\n",
       "\u001b[0;34m    case the highest predicted probabilities are tied, the classifier will\u001b[0m\n",
       "\u001b[0;34m    predict the tied class with the lowest index in :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\u001b[0m\n",
       "\u001b[0;34m           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\u001b[0m\n",
       "\u001b[0;34m           Learning\", Springer, 2009.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\u001b[0m\n",
       "\u001b[0;34m           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.datasets import load_iris\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import cross_val_score\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.tree import DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m    >>> clf = DecisionTreeClassifier(random_state=0)\u001b[0m\n",
       "\u001b[0;34m    >>> iris = load_iris()\u001b[0m\n",
       "\u001b[0;34m    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\u001b[0m\n",
       "\u001b[0;34m    ...                             # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m    ...\u001b[0m\n",
       "\u001b[0;34m    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\u001b[0m\n",
       "\u001b[0;34m            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccp_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deprecated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The training input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csc_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\u001b[0m\n",
       "\u001b[0;34m            The target values (class labels) as integers or strings.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m            Sample weights. If None, then samples are equally weighted. Splits\u001b[0m\n",
       "\u001b[0;34m            that would create child nodes with net zero or negative weight are\u001b[0m\n",
       "\u001b[0;34m            ignored while searching for a split in each node. Splits are also\u001b[0m\n",
       "\u001b[0;34m            ignored if they would result in any single class carrying a\u001b[0m\n",
       "\u001b[0;34m            negative weight in either child node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        check_input : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            Allow to bypass several input checking.\u001b[0m\n",
       "\u001b[0;34m            Don't use this parameter unless you know what you do.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        X_idx_sorted : deprecated, default=\"deprecated\"\u001b[0m\n",
       "\u001b[0;34m            This parameter is deprecated and has no effect.\u001b[0m\n",
       "\u001b[0;34m            It will be removed in 1.1 (renaming of 0.26).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            .. deprecated :: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        self : DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m            Fitted estimator.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Predict class probabilities of the input samples X.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The predicted class probability is the fraction of samples of the same\u001b[0m\n",
       "\u001b[0;34m        class in a leaf.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csr_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        check_input : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            Allow to bypass several input checking.\u001b[0m\n",
       "\u001b[0;34m            Don't use this parameter unless you know what you do.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\u001b[0m\n",
       "\u001b[0;34m            such arrays if n_outputs > 1\u001b[0m\n",
       "\u001b[0;34m            The class probabilities of the input samples. The order of the\u001b[0m\n",
       "\u001b[0;34m            classes corresponds to that in the attribute :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mall_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mall_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Predict class log-probabilities of the input samples X.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csr_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\u001b[0m\n",
       "\u001b[0;34m            such arrays if n_outputs > 1\u001b[0m\n",
       "\u001b[0;34m            The class log-probabilities of the input samples. The order of the\u001b[0m\n",
       "\u001b[0;34m            classes corresponds to that in the attribute :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.virtualenvs/pln/lib/python3.8/site-packages/sklearn/tree/_classes.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     ExtraTreeClassifier\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos listar todas las combinaciones para usarlas a mano con [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 1}\n",
      "{'criterion': 'gini', 'max_depth': 2}\n",
      "{'criterion': 'entropy', 'max_depth': 1}\n",
      "{'criterion': 'entropy', 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(params)\n",
    "    model = DecisionTreeClassifier(**params, random_state=0)\n",
    "    #model.fit(...)\n",
    "    #model.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grilla de Parámetros + Validación Cruzada\n",
    "\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) nos sirve para hacer validación cruzada sobre una grilla de parámetros. Sklearn se encarga de todo el proceso y nos devuelve una tabla de resultados y el mejor clasificador obtenido.\n",
    "\n",
    "La búsqueda se puede configurar de varias maneras. Por defecto la validación cruzada es estratificada.\n",
    "\n",
    "- [scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "cv = GridSearchCV(model, param_grid, scoring='accuracy', cv=3)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crit.\tdepth\t| mean\tstd\trank\n",
      "gini\t1\t| 0.50\t0.14\t3\n",
      "gini\t2\t| 0.61\t0.08\t1\n",
      "entropy\t1\t| 0.50\t0.14\t3\n",
      "entropy\t2\t| 0.61\t0.08\t1\n"
     ]
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "params = results['params']\n",
    "mean = results['mean_test_score']\n",
    "std = results['std_test_score']\n",
    "rank = results['rank_test_score']\n",
    "\n",
    "print(\"crit.\\tdepth\\t| mean\\tstd\\trank\")\n",
    "for p, m, s, r in zip(params, mean, std, rank):\n",
    "    print(f\"{p['criterion']}\\t{p['max_depth']}\\t| {m:0.2f}\\t{s:0.2f}\\t{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_criterion param_max_depth  mean_test_score  std_test_score  \\\n",
       "0            gini               1         0.500000        0.136083   \n",
       "1            gini               2         0.611111        0.078567   \n",
       "2         entropy               1         0.500000        0.136083   \n",
       "3         entropy               2         0.611111        0.078567   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                1  \n",
       "2                3  \n",
       "3                1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_criterion', 'param_max_depth', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plot_tree(best_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ja', 'zh'], dtype='<U2')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beijing', 'chinese', 'japan', 'macao', 'osaka', 'shangai', 'tokyo']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ja'], dtype='<U2')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(vect.transform(['chinese japan']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda Aleatoria\n",
    "\n",
    "- [Randomized Parameter Optimization](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSGDClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Linear classifiers (SVM, logistic regression, etc.) with SGD training.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This estimator implements regularized linear models with stochastic\u001b[0m\n",
       "\u001b[0;34m    gradient descent (SGD) learning: the gradient of the loss is estimated\u001b[0m\n",
       "\u001b[0;34m    each sample at a time and the model is updated along the way with a\u001b[0m\n",
       "\u001b[0;34m    decreasing strength schedule (aka learning rate). SGD allows minibatch\u001b[0m\n",
       "\u001b[0;34m    (online/out-of-core) learning via the `partial_fit` method.\u001b[0m\n",
       "\u001b[0;34m    For best results using the default learning rate schedule, the data should\u001b[0m\n",
       "\u001b[0;34m    have zero mean and unit variance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This implementation works with data represented as dense or sparse arrays\u001b[0m\n",
       "\u001b[0;34m    of floating point values for the features. The model it fits can be\u001b[0m\n",
       "\u001b[0;34m    controlled with the loss parameter; by default, it fits a linear support\u001b[0m\n",
       "\u001b[0;34m    vector machine (SVM).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The regularizer is a penalty added to the loss function that shrinks model\u001b[0m\n",
       "\u001b[0;34m    parameters towards the zero vector using either the squared euclidean norm\u001b[0m\n",
       "\u001b[0;34m    L2 or the absolute norm L1 or a combination of both (Elastic Net). If the\u001b[0m\n",
       "\u001b[0;34m    parameter update crosses the 0.0 value because of the regularizer, the\u001b[0m\n",
       "\u001b[0;34m    update is truncated to 0.0 to allow for learning sparse models and achieve\u001b[0m\n",
       "\u001b[0;34m    online feature selection.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <sgd>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    loss : str, default='hinge'\u001b[0m\n",
       "\u001b[0;34m        The loss function to be used. Defaults to 'hinge', which gives a\u001b[0m\n",
       "\u001b[0;34m        linear SVM.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The possible options are 'hinge', 'log', 'modified_huber',\u001b[0m\n",
       "\u001b[0;34m        'squared_hinge', 'perceptron', or a regression loss: 'squared_loss',\u001b[0m\n",
       "\u001b[0;34m        'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The 'log' loss gives logistic regression, a probabilistic classifier.\u001b[0m\n",
       "\u001b[0;34m        'modified_huber' is another smooth loss that brings tolerance to\u001b[0m\n",
       "\u001b[0;34m        outliers as well as probability estimates.\u001b[0m\n",
       "\u001b[0;34m        'squared_hinge' is like hinge but is quadratically penalized.\u001b[0m\n",
       "\u001b[0;34m        'perceptron' is the linear loss used by the perceptron algorithm.\u001b[0m\n",
       "\u001b[0;34m        The other losses are designed for regression but can be useful in\u001b[0m\n",
       "\u001b[0;34m        classification as well; see\u001b[0m\n",
       "\u001b[0;34m        :class:`~sklearn.linear_model.SGDRegressor` for a description.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        More details about the losses formulas can be found in the\u001b[0m\n",
       "\u001b[0;34m        :ref:`User Guide <sgd_mathematical_formulation>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    penalty : {'l2', 'l1', 'elasticnet'}, default='l2'\u001b[0m\n",
       "\u001b[0;34m        The penalty (aka regularization term) to be used. Defaults to 'l2'\u001b[0m\n",
       "\u001b[0;34m        which is the standard regularizer for linear SVM models. 'l1' and\u001b[0m\n",
       "\u001b[0;34m        'elasticnet' might bring sparsity to the model (feature selection)\u001b[0m\n",
       "\u001b[0;34m        not achievable with 'l2'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    alpha : float, default=0.0001\u001b[0m\n",
       "\u001b[0;34m        Constant that multiplies the regularization term. The higher the\u001b[0m\n",
       "\u001b[0;34m        value, the stronger the regularization.\u001b[0m\n",
       "\u001b[0;34m        Also used to compute the learning rate when set to `learning_rate` is\u001b[0m\n",
       "\u001b[0;34m        set to 'optimal'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    l1_ratio : float, default=0.15\u001b[0m\n",
       "\u001b[0;34m        The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\u001b[0m\n",
       "\u001b[0;34m        l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.\u001b[0m\n",
       "\u001b[0;34m        Only used if `penalty` is 'elasticnet'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fit_intercept : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        Whether the intercept should be estimated or not. If False, the\u001b[0m\n",
       "\u001b[0;34m        data is assumed to be already centered.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_iter : int, default=1000\u001b[0m\n",
       "\u001b[0;34m        The maximum number of passes over the training data (aka epochs).\u001b[0m\n",
       "\u001b[0;34m        It only impacts the behavior in the ``fit`` method, and not the\u001b[0m\n",
       "\u001b[0;34m        :meth:`partial_fit` method.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    tol : float, default=1e-3\u001b[0m\n",
       "\u001b[0;34m        The stopping criterion. If it is not None, training will stop\u001b[0m\n",
       "\u001b[0;34m        when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive\u001b[0m\n",
       "\u001b[0;34m        epochs.\u001b[0m\n",
       "\u001b[0;34m        Convergence is checked against the training loss or the\u001b[0m\n",
       "\u001b[0;34m        validation loss depending on the `early_stopping` parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    shuffle : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        Whether or not the training data should be shuffled after each epoch.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    verbose : int, default=0\u001b[0m\n",
       "\u001b[0;34m        The verbosity level.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    epsilon : float, default=0.1\u001b[0m\n",
       "\u001b[0;34m        Epsilon in the epsilon-insensitive loss functions; only if `loss` is\u001b[0m\n",
       "\u001b[0;34m        'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\u001b[0m\n",
       "\u001b[0;34m        For 'huber', determines the threshold at which it becomes less\u001b[0m\n",
       "\u001b[0;34m        important to get the prediction exactly right.\u001b[0m\n",
       "\u001b[0;34m        For epsilon-insensitive, any differences between the current prediction\u001b[0m\n",
       "\u001b[0;34m        and the correct label are ignored if they are less than this threshold.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of CPUs to use to do the OVA (One Versus All, for\u001b[0m\n",
       "\u001b[0;34m        multi-class problems) computation.\u001b[0m\n",
       "\u001b[0;34m        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\u001b[0m\n",
       "\u001b[0;34m        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\u001b[0m\n",
       "\u001b[0;34m        for more details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int, RandomState instance, default=None\u001b[0m\n",
       "\u001b[0;34m        Used for shuffling the data, when ``shuffle`` is set to ``True``.\u001b[0m\n",
       "\u001b[0;34m        Pass an int for reproducible output across multiple function calls.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    learning_rate : str, default='optimal'\u001b[0m\n",
       "\u001b[0;34m        The learning rate schedule:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - 'constant': `eta = eta0`\u001b[0m\n",
       "\u001b[0;34m        - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\u001b[0m\n",
       "\u001b[0;34m          where t0 is chosen by a heuristic proposed by Leon Bottou.\u001b[0m\n",
       "\u001b[0;34m        - 'invscaling': `eta = eta0 / pow(t, power_t)`\u001b[0m\n",
       "\u001b[0;34m        - 'adaptive': eta = eta0, as long as the training keeps decreasing.\u001b[0m\n",
       "\u001b[0;34m          Each time n_iter_no_change consecutive epochs fail to decrease the\u001b[0m\n",
       "\u001b[0;34m          training loss by tol or fail to increase validation score by tol if\u001b[0m\n",
       "\u001b[0;34m          early_stopping is True, the current learning rate is divided by 5.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            .. versionadded:: 0.20\u001b[0m\n",
       "\u001b[0;34m                Added 'adaptive' option\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    eta0 : double, default=0.0\u001b[0m\n",
       "\u001b[0;34m        The initial learning rate for the 'constant', 'invscaling' or\u001b[0m\n",
       "\u001b[0;34m        'adaptive' schedules. The default value is 0.0 as eta0 is not used by\u001b[0m\n",
       "\u001b[0;34m        the default schedule 'optimal'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    power_t : double, default=0.5\u001b[0m\n",
       "\u001b[0;34m        The exponent for inverse scaling learning rate [default 0.5].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    early_stopping : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        Whether to use early stopping to terminate training when validation\u001b[0m\n",
       "\u001b[0;34m        score is not improving. If set to True, it will automatically set aside\u001b[0m\n",
       "\u001b[0;34m        a stratified fraction of training data as validation and terminate\u001b[0m\n",
       "\u001b[0;34m        training when validation score returned by the `score` method is not\u001b[0m\n",
       "\u001b[0;34m        improving by at least tol for n_iter_no_change consecutive epochs.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.20\u001b[0m\n",
       "\u001b[0;34m            Added 'early_stopping' option\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    validation_fraction : float, default=0.1\u001b[0m\n",
       "\u001b[0;34m        The proportion of training data to set aside as validation set for\u001b[0m\n",
       "\u001b[0;34m        early stopping. Must be between 0 and 1.\u001b[0m\n",
       "\u001b[0;34m        Only used if `early_stopping` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.20\u001b[0m\n",
       "\u001b[0;34m            Added 'validation_fraction' option\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_iter_no_change : int, default=5\u001b[0m\n",
       "\u001b[0;34m        Number of iterations with no improvement to wait before stopping\u001b[0m\n",
       "\u001b[0;34m        fitting.\u001b[0m\n",
       "\u001b[0;34m        Convergence is checked against the training loss or the\u001b[0m\n",
       "\u001b[0;34m        validation loss depending on the `early_stopping` parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.20\u001b[0m\n",
       "\u001b[0;34m            Added 'n_iter_no_change' option\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    class_weight : dict, {class_label: weight} or \"balanced\", default=None\u001b[0m\n",
       "\u001b[0;34m        Preset for the class_weight fit parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Weights associated with classes. If not given, all classes\u001b[0m\n",
       "\u001b[0;34m        are supposed to have weight one.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
       "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
       "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    warm_start : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        When set to True, reuse the solution of the previous call to fit as\u001b[0m\n",
       "\u001b[0;34m        initialization, otherwise, just erase the previous solution.\u001b[0m\n",
       "\u001b[0;34m        See :term:`the Glossary <warm_start>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Repeatedly calling fit or partial_fit when warm_start is True can\u001b[0m\n",
       "\u001b[0;34m        result in a different solution than when calling fit a single time\u001b[0m\n",
       "\u001b[0;34m        because of the way the data is shuffled.\u001b[0m\n",
       "\u001b[0;34m        If a dynamic learning rate is used, the learning rate is adapted\u001b[0m\n",
       "\u001b[0;34m        depending on the number of samples already seen. Calling ``fit`` resets\u001b[0m\n",
       "\u001b[0;34m        this counter, while ``partial_fit`` will result in increasing the\u001b[0m\n",
       "\u001b[0;34m        existing counter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    average : bool or int, default=False\u001b[0m\n",
       "\u001b[0;34m        When set to True, computes the averaged SGD weights accross all\u001b[0m\n",
       "\u001b[0;34m        updates and stores the result in the ``coef_`` attribute. If set to\u001b[0m\n",
       "\u001b[0;34m        an int greater than 1, averaging will begin once the total number of\u001b[0m\n",
       "\u001b[0;34m        samples seen reaches `average`. So ``average=10`` will begin\u001b[0m\n",
       "\u001b[0;34m        averaging after seeing 10 samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    coef_ : ndarray of shape (1, n_features) if n_classes == 2 else \\\u001b[0m\n",
       "\u001b[0;34m            (n_classes, n_features)\u001b[0m\n",
       "\u001b[0;34m        Weights assigned to the features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\u001b[0m\n",
       "\u001b[0;34m        Constants in decision function.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_iter_ : int\u001b[0m\n",
       "\u001b[0;34m        The actual number of iterations before reaching the stopping criterion.\u001b[0m\n",
       "\u001b[0;34m        For multiclass fits, it is the maximum over every binary fit.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    loss_function_ : concrete ``LossFunction``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    classes_ : array of shape (n_classes,)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    t_ : int\u001b[0m\n",
       "\u001b[0;34m        Number of weight updates performed during training.\u001b[0m\n",
       "\u001b[0;34m        Same as ``(n_iter_ * n_samples)``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    sklearn.svm.LinearSVC : Linear support vector classification.\u001b[0m\n",
       "\u001b[0;34m    LogisticRegression : Logistic regression.\u001b[0m\n",
       "\u001b[0;34m    Perceptron : Inherits from SGDClassifier. ``Perceptron()`` is equivalent to\u001b[0m\n",
       "\u001b[0;34m        ``SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\",\u001b[0m\n",
       "\u001b[0;34m        penalty=None)``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.linear_model import SGDClassifier\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.preprocessing import StandardScaler\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.pipeline import make_pipeline\u001b[0m\n",
       "\u001b[0;34m    >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\u001b[0m\n",
       "\u001b[0;34m    >>> Y = np.array([1, 1, 2, 2])\u001b[0m\n",
       "\u001b[0;34m    >>> # Always scale the input. The most convenient way is to use a pipeline.\u001b[0m\n",
       "\u001b[0;34m    >>> clf = make_pipeline(StandardScaler(),\u001b[0m\n",
       "\u001b[0;34m    ...                     SGDClassifier(max_iter=1000, tol=1e-3))\u001b[0m\n",
       "\u001b[0;34m    >>> clf.fit(X, Y)\u001b[0m\n",
       "\u001b[0;34m    Pipeline(steps=[('standardscaler', StandardScaler()),\u001b[0m\n",
       "\u001b[0;34m                    ('sgdclassifier', SGDClassifier())])\u001b[0m\n",
       "\u001b[0;34m    >>> print(clf.predict([[-0.8, -1]]))\u001b[0m\n",
       "\u001b[0;34m    [1]\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hinge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_EPSILON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"optimal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"modified_huber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"probability estimates are not available for\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0;34m\" loss=%r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Probability estimates.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This method is only available for log loss and modified Huber loss.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Multiclass probability estimates are derived from binary (one-vs.-rest)\u001b[0m\n",
       "\u001b[0;34m        estimates by simple normalization, as recommended by Zadrozny and\u001b[0m\n",
       "\u001b[0;34m        Elkan.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Binary probability estimates for loss=\"modified_huber\" are given by\u001b[0m\n",
       "\u001b[0;34m        (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions\u001b[0m\n",
       "\u001b[0;34m        it is necessary to perform proper probability calibration by wrapping\u001b[0m\n",
       "\u001b[0;34m        the classifier with\u001b[0m\n",
       "\u001b[0;34m        :class:`~sklearn.calibration.CalibratedClassifierCV` instead.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix}, shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Input data for prediction.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        ndarray of shape (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Returns the probability of the sample for each class in the model,\u001b[0m\n",
       "\u001b[0;34m            where classes are ordered as they are in `self.classes_`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        References\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        Zadrozny and Elkan, \"Transforming classifier scores into multiclass\u001b[0m\n",
       "\u001b[0;34m        probability estimates\", SIGKDD'02,\u001b[0m\n",
       "\u001b[0;34m        http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The justification for the formula in the loss=\"modified_huber\"\u001b[0m\n",
       "\u001b[0;34m        case is in the appendix B in:\u001b[0m\n",
       "\u001b[0;34m        http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"log\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"modified_huber\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprob\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# the above might assign zero to all classes, which doesn't\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# normalize neatly; work around this to produce uniform\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# probabilities\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mall_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprob_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprob_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_zero\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# normalize\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprob\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mprob_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict_(log_)proba only supported when\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0;34m\" loss='log' or loss='modified_huber' \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0;34m\"(%r given)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Log of probability estimates.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This method is only available for log loss and modified Huber loss.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        When loss=\"modified_huber\", probability estimates may be hard zeros\u001b[0m\n",
       "\u001b[0;34m        and ones, so taking the logarithm is not possible.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        See ``predict_proba`` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Input data for prediction.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        T : array-like, shape (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Returns the log-probability of the sample for each class in the\u001b[0m\n",
       "\u001b[0;34m            model, where classes are ordered as they are in\u001b[0m\n",
       "\u001b[0;34m            `self.classes_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_log_proba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_predict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m'_xfail_checks'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m'check_sample_weights_invariance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m'zero sample_weight is not equivalent to removing samples'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.virtualenvs/pln/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy import stats\n",
    "\n",
    "param_dist = {\n",
    "    'loss': [\n",
    "        'hinge',        # SVM\n",
    "        'log',          # logistic regression\n",
    "        #'preceptron',  # perceptron (not supported)\n",
    "    ],\n",
    "    'alpha': loguniform(1e-4, 1e2),  # de 0.0001 a 100.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos muestrear mano con [ParameterSampler](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.196282248134428, 'loss': 'log'}\n",
      "{'alpha': 11.630395714480306, 'loss': 'log'}\n",
      "{'alpha': 0.18590843630169634, 'loss': 'log'}\n",
      "{'alpha': 0.5512926225087423, 'loss': 'hinge'}\n",
      "{'alpha': 0.042220489831498266, 'loss': 'hinge'}\n",
      "{'alpha': 0.0002189161813274828, 'loss': 'hinge'}\n",
      "{'alpha': 0.01998246739232945, 'loss': 'hinge'}\n",
      "{'alpha': 7.46470024356059, 'loss': 'hinge'}\n",
      "{'alpha': 0.256016152500287, 'loss': 'log'}\n",
      "{'alpha': 10.386580256500283, 'loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "for params in ParameterSampler(param_dist, 10, random_state=0):\n",
    "    print(params)\n",
    "    model = SGDClassifier(**params, random_state=0)\n",
    "    #model.fit(...)\n",
    "    #model.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda Aleatoria + Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos dejar que Sklearn se encargue de todo con [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = SGDClassifier(random_state=0)\n",
    "\n",
    "cv = RandomizedSearchCV(model, param_dist, n_iter=10, cv=3, random_state=0)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log</td>\n",
       "      <td>0.196282</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log</td>\n",
       "      <td>11.630396</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log</td>\n",
       "      <td>0.185908</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.04222</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hinge</td>\n",
       "      <td>7.4647</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>log</td>\n",
       "      <td>0.256016</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hinge</td>\n",
       "      <td>10.38658</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_loss param_alpha  mean_test_score  std_test_score  rank_test_score\n",
       "0        log    0.196282         0.888889        0.157135                2\n",
       "1        log   11.630396         0.888889        0.157135                2\n",
       "2        log    0.185908         0.888889        0.157135                2\n",
       "3      hinge    0.551293         0.888889        0.157135                2\n",
       "4      hinge     0.04222         0.888889        0.157135                2\n",
       "5      hinge    0.000219         0.888889        0.157135                2\n",
       "6      hinge    0.019982         1.000000        0.000000                1\n",
       "7      hinge      7.4647         0.888889        0.157135                2\n",
       "8        log    0.256016         0.888889        0.157135                2\n",
       "9      hinge    10.38658         0.888889        0.157135                2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = cv.cv_results_\n",
    "df = pd.DataFrame(results)\n",
    "df[['param_loss', 'param_alpha', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01998246739232945, random_state=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01998246739232945, 'loss': 'hinge'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "Scikit-learn:\n",
    "\n",
    "- [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
