{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regresión\n",
    "\n",
    "Revisaremos los conceptos de regresión vistos en el teórico.\n",
    "\n",
    "Haremos pruebas con datos de entrada de **una dimensión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)  # no usar notacion \"e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función Verdadera Oculta\n",
    "\n",
    "Usaremos como función oculta un sinusoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sinusoidal_data(spread=0.25, data_size=50):\n",
    "    np.random.seed(0)\n",
    "    x = np.linspace(0, 1, data_size)\n",
    "    y = np.sin(2 * np.pi * x) + np.random.normal(scale=spread, size=x.shape)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f_x = create_sinusoidal_data(0, 100)\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestra Ruidosa\n",
    "\n",
    "Tomaremos puntos uniformes en $x$, ruidosos en $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 20\n",
    "X, y = create_sinusoidal_data(0.10, data_size)\n",
    "\n",
    "plt.scatter(X, y, color=\"blue\", label=\"datos\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en Entrenamiento y Evaluación\n",
    "\n",
    "Dividiremos aleatoriamente los datos en una parte para entrenamiento y otra para evaluación.\n",
    "\n",
    "Usaremos \n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 5\n",
    "val_size = data_size - train_size\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=train_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "#plt.scatter(X_val, y_val, color=\"white\", edgecolor=\"k\", label=\"val\")\n",
    "#plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "Probaremos ajustar los puntos usando una recta.\n",
    "\n",
    "Vamos a programar a mano el aprendizaje y la predicción.\n",
    "\n",
    "### Solución de Cuadrados Mínimos\n",
    "\n",
    "Datos de entrenamiento:\n",
    "- $X \\in R^{N \\times K}:$ $N$ vectores de entrada, de $K$ dimensiones cada uno.\n",
    "- $y \\in R^N:$ $N$ valores de salida.\n",
    "\n",
    "Aprendizaje:\n",
    "\n",
    "$$w^* = (X^\\top X)^{-1} X^\\top y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción:\n",
    "\n",
    "$$f_{w^*}(x) = x^\\top w^* = \\sum_{k=1}^K x_k w^*_k$$\n",
    "\n",
    "Con $K=1$ tendríamos:\n",
    "\n",
    "$$f_{w^*}(x) = x_1 w_1^*$$\n",
    "\n",
    "Para que sea una recta nos falta un $w_0$ (\"bias\").\n",
    "Esto se puede resolver haciendo $K=2$ y agregando un valor constante 1 a cada dato:\n",
    "\n",
    "$$f_{w^*}((1, x)) = w_0 + x_1 w_1^*$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bias = np.stack((np.ones(X_train.shape[0]), X_train), axis=1)  # add bias\n",
    "X_train_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_least_squares(X, y):\n",
    "    X_b = np.stack((X, np.ones(X.shape[0])), axis=1)  # add bias\n",
    "    return np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T.dot(y))\n",
    "\n",
    "def f(X, w):\n",
    "    X_b = np.stack((X, np.ones(X.shape[0])), axis=1)  # add bias: (1, x)\n",
    "    return X_b.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = linear_least_squares(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w  # qué dimensiones tiene w?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar\n",
    "\n",
    "Graficaremos la función aprendida a partir de los datos de entrenamiento. También graficaremos con los datos de evaluación y la función oculta, para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.plot(x, f(x, w), color=\"red\", label=\"model\")\n",
    "plt.scatter(X_val, y_val, color=\"white\", edgecolor=\"k\", label=\"val\")\n",
    "#plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir y Evaluar: Error Cuadrático Medio\n",
    "\n",
    "Obtendremos los valores predichos para los datos de entrenamiento y de evaluación.\n",
    "Calcularemos el error cuadrático medio sobre ambos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = f(X_train, w)\n",
    "y_val_pred = f(X_val, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la función [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) de scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_error = mean_squared_error(y_train, y_train_pred)\n",
    "val_error = mean_squared_error(y_val, y_val_pred)\n",
    "print(f'Train error: {train_error:f}')\n",
    "print(f'Val error: {val_error:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Polinomial\n",
    "\n",
    "Ahora haremos regresión polinomial. En este caso usaremos scikit-learn para definir el modelo, entrenar y predecir.\n",
    "\n",
    "En scikit-learn cada dato de entrada debe ser un vector, no un número. Debemos convertir cada dato en un vector de una dimensión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1)\n",
    "X_val = X_val.reshape(-1, 1)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Polinomiales\n",
    "\n",
    "En scikit-learn, la regresión polinomial se implementa como un modelo de dos pasos.\n",
    "\n",
    "El primer paso genera vectores de características polinomiales, y el segundo paso aplica una regresión lineal sobre estos vectores (ver [Polynomial interpolation](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html)).\n",
    "\n",
    "$$[1, x, x^2, x^3, x^4, x^5]$$\n",
    "\n",
    "Por ejemplo, para generar características polinomiales de grado 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pf = PolynomialFeatures(5)  # polinomio de grado 5\n",
    "pf.fit(X_train)             # no necesita y_train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `tranform()` convertimos los datos de train en carácteristicas polinómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape  # qué forma tiene esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar y Entrenar\n",
    "\n",
    "Crearemos y entrenaremos un modelo de grado 2.\n",
    "\n",
    "Como siempre en scikit-learn, para entrenar usamos la función **fit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "degree = 2\n",
    "pf = PolynomialFeatures(degree)\n",
    "lr = LinearRegression(fit_intercept=False)  # el bias ya esta como feature\n",
    "model = make_pipeline(pf, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalente a:\n",
    "Z_train = pf.fit_transform(X_train, y_train)\n",
    "lr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspeccionar Parámetros\n",
    "\n",
    "Ver [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "plt.scatter(X_val, y_val, color=\"white\", edgecolor=\"k\", label=\"val\")\n",
    "#plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir y Evaluar\n",
    "\n",
    "Para predecir, usamos la función **predict**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, y_train_pred)\n",
    "val_error = mean_squared_error(y_val, y_val_pred)\n",
    "print(f'Train error: {train_error:0.2}')\n",
    "print(f'Test error: {val_error:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste vs. Generalización\n",
    "\n",
    "Probaremos polinomios de varios grados, obteniendo valores de error en entrenamiento y evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "val_errors = []\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for degree in degrees:\n",
    "    # train:\n",
    "    pf = PolynomialFeatures(degree)\n",
    "    lr = LinearRegression(fit_intercept=False)\n",
    "    model = make_pipeline(pf, lr)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict:\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # evaluate:\n",
    "    train_error = mean_squared_error(y_train, y_train_pred)\n",
    "    val_error = mean_squared_error(y_val, y_val_pred)\n",
    "    train_errors.append(train_error)\n",
    "    val_errors.append(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors, val_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficaremos las curvas de error en términos del grado del polinomio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, train_errors, color=\"blue\", label=\"train\")\n",
    "plt.plot(degrees, val_errors, color=\"red\", label=\"val\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el error en entrenamiento siempre baja, pero que en algún punto comienza el sobreajuste, ya que el error en evaluación empieza a subir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor Modelo\n",
    "\n",
    "De acuerdo a la gráfica anterior, y como era de esperarse, el modelo que mejor ajusta los datos es el de grado 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model.fit(X_train, y_train);\n",
    "model.named_steps[\"linearregression\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_val, y_val, color=\"white\", edgecolor=\"k\", label=\"val\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "#plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors[3], val_errors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Sobreajustado\n",
    "\n",
    "Veamos cómo es la gráfica de uno de los modelos que sufre de sobreajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 27\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model.fit(X_train, y_train);\n",
    "model.named_steps[\"linearregression\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_val, y_val, color=\"white\", edgecolor=\"k\", label=\"val\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "#plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Probar agregando puntos a los datos de entrenamiento para prevenir el sobreajuste en polinomios de grado alto.\n",
    "2. Imprimir los parámetros de los modelos para cada grado.\n",
    "3. Probar usando regularización para prevenir el sobreajuste en polinomios de grado alto\n",
    "(ver [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)).\n",
    "4. Hicimos todo con datos de entrada de una dimensión. ¿Cómo serían los features polinomiales en datos de 2 o más dimensiones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Scikit-learn:\n",
    "\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
    "- [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
