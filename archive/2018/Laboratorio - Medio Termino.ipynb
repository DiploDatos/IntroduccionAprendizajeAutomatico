{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1: Conceptos básicos de aprendizaje automático\n",
    "\n",
    "En el laboratorio les tocará probar con distintos parámetros de los algoritmos de aprendizaje automático aprendidos hasta ahora. La idea es que vean como la selección de atributos, el cambio de hiperparámetros, y los distintos algoritmos afectan los resultados de un clasificador sobre u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ml.visualization import plot_confusion_matrix, classifier_boundary\n",
    "from sklearn.datasets import load_boston, load_breast_cancer, load_iris\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "np.random.seed(1234)  # Setup seed to be more deterministic\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión\n",
    "\n",
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boston_data = load_boston()\n",
    "\n",
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación\n",
    "shuff_data = np.random.permutation(506)\n",
    "shuff_train = shuff_data[:400]\n",
    "shuff_val = shuff_data[400:]\n",
    "\n",
    "X_train = boston_data['data'][shuff_train]\n",
    "X_val = boston_data['data'][shuff_val]\n",
    "\n",
    "y_train = boston_data['target'][shuff_train]\n",
    "y_val = boston_data['target'][shuff_val]\n",
    "\n",
    "# Necesario para poder hacer un regresor por feature\n",
    "feature_map = {feature: idx for idx, feature in enumerate(boston_data['feature_names'])}\n",
    "\n",
    "print(boston_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión sin regularización\n",
    "\n",
    "Para revisar como afecta el cambio de parámetros y los distintos tipos de regresores y atributos (características) al resultado final del algoritmo de aprendizaje automático, lo que se va a hacer es entrenar el regresor tomando sólo un atributo y visualizar eso.\n",
    "\n",
    "Se busca entrenar utilizando el conjunto de entrenamiento (el terminado en `train`) y evaluar utilizando el conjunto de validación (el terminado en `val`). Luego se visualiza la función calculada para cada conjunto y se la compara.\n",
    "\n",
    "Los atributos posibles están listados en la descripción del conjunto de datos en la celda anterior. No todos son útiles para visualizar, en particular solo nos interesan los atributos numéricos y descartamos los atributos que se listan a continuación:\n",
    "\n",
    "- `CHAS`: Atributo categórico (toma valor 0 o 1).\n",
    "- `RAD`: Atributo categórico (índice).\n",
    "- `MEDV`: Este valor se lo lista como atributo en la descripción del conjunto de datos pero en realidad es el valor de `y`, i.e. es el valor que tratamos de aproximar con el algoritmo de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos un atributo de los listados en la descripción que no sea categórico\n",
    "selected_feature = 'AGE'  # TODO: modificar esto por algún otro valor para ver como cambian los resultados\n",
    "feature_col = feature_map[selected_feature]\n",
    "X_train_feature = X_train[:, feature_col].reshape(-1, 1)  # Hay que ser que sea una matriz no un vector para que funcione con scikit learn\n",
    "X_val_feature = X_val[:, feature_col].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos un clasificador utilizando sólo ese atributo sobre el conjunto de entrenamiento (X_train, y_train)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "# Evaluamos el desempeño del clasificador utilizando la media del error cuadrado (MSE o mean squared error)\n",
    "# sobre el conjunto de datos de entrenamiento (X_train, y_train) y lo comparamos con el de validación (X_val, y_val)\n",
    "# Mientras más cercano a cero mejor\n",
    "print('Media del error cuadrado para entrenamiento: %.2f' % \n",
    "      mean_squared_error(y_train, model.predict(X_train_feature)))\n",
    "print('Media del error cuadrado para validación: %.2f' %\n",
    "      mean_squared_error(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_range_start = np.min(np.r_[X_train_feature, X_val_feature])\n",
    "X_range_stop = np.max(np.r_[X_train_feature, X_val_feature])\n",
    "y_range_start = np.min(np.r_[y_train, y_val])\n",
    "y_range_stop = np.max(np.r_[y_train, y_val])\n",
    "X_linspace = np.linspace(X_range_start, X_range_stop, 200).reshape(-1, 1)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_feature, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_val_feature, y_val, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_degree = # TODO: Probar distintos grados del polinomio\n",
    "\n",
    "poly_features = PolynomialFeatures(polynomial_degree)\n",
    "poly_features.fit(X_train_feature)\n",
    "X_poly_train = poly_features.transform(X_train_feature)\n",
    "X_poly_val = poly_features.transform(X_val_feature)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "print('Media del error cuadrado para entrenamiento: %.2f' % \n",
    "      mean_squared_error(y_train, model.predict(X_poly_train)))\n",
    "print('Media del error cuadrado para validación: %.2f' %\n",
    "      mean_squared_error(y_val, model.predict(X_poly_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_range_start = np.min(np.r_[X_train_feature, X_val_feature])\n",
    "X_range_stop = np.max(np.r_[X_train_feature, X_val_feature])\n",
    "y_range_start = np.min(np.r_[y_train, y_val])\n",
    "y_range_stop = np.max(np.r_[y_train, y_val])\n",
    "X_linspace = np.linspace(X_range_start, X_range_stop, 200).reshape(-1, 1)\n",
    "X_linspace_poly = poly_features.transform(X_linspace)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_feature, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace_poly), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_val_feature, y_val, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace_poly), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con regularización\n",
    "\n",
    "#### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = # TODO: Parámetro de regularización. También denominado como parámetro `lambda`.\n",
    "max_iter = # TODO: Cantidad máxima de iteraciones del algoritmo\n",
    "tol = # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente)\n",
    "\n",
    "model = Ridge(alpha=alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "print('Media del error cuadrado para entrenamiento: %.2f' % \n",
    "      mean_squared_error(y_train, model.predict(X_train_feature)))\n",
    "print('Media del error cuadrado para validación: %.2f' %\n",
    "      mean_squared_error(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_range_start = np.min(np.r_[X_train_feature, X_val_feature])\n",
    "X_range_stop = np.max(np.r_[X_train_feature, X_val_feature])\n",
    "y_range_start = np.min(np.r_[y_train, y_val])\n",
    "y_range_stop = np.max(np.r_[y_train, y_val])\n",
    "X_linspace = np.linspace(X_range_start, X_range_stop, 200).reshape(-1, 1)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_feature, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_val_feature, y_val, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_degree =  # TODO: Grado del polinomio.\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente)\n",
    "\n",
    "poly_features = PolynomialFeatures(polynomial_degree)\n",
    "poly_features.fit(X_train_feature)\n",
    "X_poly_train = poly_features.transform(X_train_feature)\n",
    "X_poly_val = poly_features.transform(X_val_feature)\n",
    "\n",
    "model = Ridge(alpha=alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "print('Media del error cuadrado para entrenamiento: %.2f' % \n",
    "      mean_squared_error(y_train, model.predict(X_poly_train)))\n",
    "print('Media del error cuadrado para validación: %.2f' %\n",
    "      mean_squared_error(y_val, model.predict(X_poly_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de la regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "X_range_start = np.min(np.r_[X_train_feature, X_val_feature])\n",
    "X_range_stop = np.max(np.r_[X_train_feature, X_val_feature])\n",
    "y_range_start = np.min(np.r_[y_train, y_val])\n",
    "y_range_stop = np.max(np.r_[y_train, y_val])\n",
    "X_linspace = np.linspace(X_range_start, X_range_stop, 200).reshape(-1, 1)\n",
    "X_linspace_poly = poly_features.transform(X_linspace)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_feature, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace_poly), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_val_feature, y_val, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "plt.plot(X_linspace, model.predict(X_linspace_poly), color=\"tomato\", label=\"modelo\")\n",
    "plt.ylim(y_range_start, y_range_stop)\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación binaria\n",
    "\n",
    "La clasificación binaria tiene dos posibles etiquetas para su clasificación: SI y NO (o 0 y 1, o -1 y 1). Nuevamente, se busca entrenar utilizando el conjunto de entrenamiento (el terminado en `train`) y evaluar utilizando el conjunto de validación (el terminado en `val`). Luego se visualiza la función calculada para cada conjunto y se la compara.\n",
    "\n",
    "Similar al caso anterior, para poder visualizar los distintos atributos y como estos afectan el modelo, debemos hacer uso de una selección de atributos a mano. En este caso todos los atributos son válidos, puesto que todos son numéricos. Como en este caso tenemos una clasificación, lo que buscamos ver es la frontera de decisión eligiendo distintos atributos y parámetros para distintos clasificadores. En este caso elegimos 2 atributos ya que la clase se representará por color dentro del gráfico.\n",
    "\n",
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "breast_cancer_data = load_breast_cancer()\n",
    "\n",
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación\n",
    "shuff_data = np.random.permutation(569)\n",
    "shuff_train = shuff_data[:400]\n",
    "shuff_val = shuff_data[400:]\n",
    "\n",
    "X_train = breast_cancer_data['data'][shuff_train]\n",
    "X_val = breast_cancer_data['data'][shuff_val]\n",
    "\n",
    "y_train = breast_cancer_data['target'][shuff_train]\n",
    "y_val = breast_cancer_data['target'][shuff_val]\n",
    "\n",
    "feature_map = {feature: idx for idx, feature in enumerate(breast_cancer_data['feature_names'])}\n",
    "\n",
    "print(breast_cancer_data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Listado de atributos\\n====================\")\n",
    "for feature in breast_cancer_data['feature_names']:\n",
    "    print(\"- %s\" % feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos dos atributo de los listados en el apartado anterior, uno para el eje x y otro para el eje y\n",
    "# TODO: cambiar con estos features\n",
    "x_feature = 'mean radius'\n",
    "y_feature = 'mean texture'\n",
    "\n",
    "x_feature_col = feature_map[x_feature]\n",
    "y_feature_col = feature_map[y_feature]\n",
    "X_train_feature = X_train[:, [x_feature_col, y_feature_col]]\n",
    "X_val_feature = X_val[:, [x_feature_col, y_feature_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty =  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados), elasticnet (l1 + l2).\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente)\n",
    "eta =  # TODO: Parámetro de actualización de los pesos. También denominado como parámetro `alpha`.\n",
    "\n",
    "model = Perceptron(penalty=penalty, alpha=alpha, max_iter=max_iter, tol=tol, eta0=eta)\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "# Evaluamos el desempeño del clasificador utilizando la exactitud (accuracy) sobre el conjunto\n",
    "# de datos de entrenamiento (X_train, y_train) y lo comparamos con el de validación (X_val, y_val)\n",
    "# La exactitud toma valor en el rango [0, 1] donde más alto es mejor\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train_feature)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión\n",
    "\n",
    "La matriz de confusión sirve en clasificación para ver que tanto se desviaron las instancias (de entrenamiento o de validación) de su valor real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística con atributos regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty =  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train_feature)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística con atributos polinomiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_degree =  # TODO: Grado del polinomio.\n",
    "penalty =  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "poly_features = PolynomialFeatures(polynomial_degree)\n",
    "poly_features.fit(X_train_feature)\n",
    "X_poly_train = poly_features.transform(X_train_feature)\n",
    "X_poly_val = poly_features.transform(X_val_feature)\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_poly_train)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_poly_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_poly_train)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_poly_train)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_poly_val)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_poly_val)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model, poly_features)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors =  # TODO: Cantidad de vecinos a tener en cuenta\n",
    "metric =  # TODO: Medida de distancia. Algunas opciones: cosine, euclidean, manhattan.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train_feature)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=breast_cancer_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación multiclase\n",
    "\n",
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación multiclase\n",
    "\n",
    "Ahora veremos clasificación binaria. Muy similar al caso anterior, con la diferencia de que en este caso hay más de dos etiquetas posibles para clasificación. La metodología en sí es muy similar al caso anterior, con la diferencia de que se utilizará el método `one-vs-all` (o también `one-vs-rest`) para hacer posible la clasificaicón.\n",
    "\n",
    "Una vez más tenemos que decidir dos features para poder visualizar los modelos.\n",
    "\n",
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "\n",
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación\n",
    "shuff_data = np.random.permutation(150)\n",
    "shuff_train = shuff_data[:120]\n",
    "shuff_val = shuff_data[120:]\n",
    "\n",
    "X_train = iris_data['data'][shuff_train]\n",
    "X_val = iris_data['data'][shuff_val]\n",
    "\n",
    "y_train = iris_data['target'][shuff_train]\n",
    "y_val = iris_data['target'][shuff_val]\n",
    "\n",
    "feature_map = {feature: idx for idx, feature in enumerate(iris_data['feature_names'])}\n",
    "\n",
    "print(iris_data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Listado de atributos\\n====================\")\n",
    "for feature in iris_data['feature_names']:\n",
    "    print(\"- %s\" % feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos dos atributo de los listados en el apartado anterior, uno para el eje x y otro para el eje y\n",
    "# TODO: Cambiar los atributos y ver como se modifica el resultado\n",
    "x_feature = 'sepal length (cm)'\n",
    "y_feature = 'sepal width (cm)'\n",
    "\n",
    "x_feature_col = feature_map[x_feature]\n",
    "y_feature_col = feature_map[y_feature]\n",
    "X_train_feature = X_train[:, [x_feature_col, y_feature_col]]\n",
    "X_val_feature = X_val[:, [x_feature_col, y_feature_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística con atributos regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty =  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol, multi_class='ovr')\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train_feature)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue', 'goldenrod'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue', 'palegoldenrod'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística con atributos polinomiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_degree =  # TODO: Grado del polinomio.\n",
    "penalty =  # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha =  # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter =  # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "tol =  # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "poly_features = PolynomialFeatures(polynomial_degree)\n",
    "poly_features.fit(X_train_feature)\n",
    "X_poly_train = poly_features.transform(X_train_feature)\n",
    "X_poly_val = poly_features.transform(X_val_feature)\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol, multi_class='ovr')\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_poly_train)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_poly_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_poly_train)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_poly_train)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_poly_val)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_poly_val)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model, poly_features)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue', 'goldenrod'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue', 'palegoldenrod'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors =  # TODO: Cantidad de vecinos a tener en cuenta\n",
    "metric =  # TODO: Medida de distancia. Algunas opciones: cosine, euclidean, manhattan.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train_feature)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_val, model.predict(X_val_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train_feature)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=iris_data.target_names,\n",
    "                      title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_val, model.predict(X_val_feature)),\n",
    "                      classes=iris_data.target_names, normalize=True,\n",
    "                      title='Matriz de confusión para validación (normalizando)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "xx, yy, Z = classifier_boundary(np.r_[X_train_feature, X_val_feature], model)\n",
    "\n",
    "cmap_dots = ListedColormap(['tomato', 'dodgerblue', 'goldenrod'])\n",
    "cmap_back = ListedColormap(['lightcoral', 'skyblue', 'palegoldenrod'])\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_train_feature[:, 0], X_train_feature[:, 1], c=y_train, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Entrenamiento\")\n",
    "\n",
    "# Conjunto de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_back)\n",
    "plt.scatter(X_val_feature[:, 0], X_val_feature[:, 1], c=y_val, cmap=cmap_dots, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Conjunto de Validación\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
