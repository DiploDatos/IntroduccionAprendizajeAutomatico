{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes: Un Ejemplo\n",
    "\n",
    "Haremos un ejemplo para ilustrar el clasificador Naive Bayes.\n",
    "\n",
    "En este ejemplo, clasificaremos textos según hablen de China ('zh') o Japón ('ja')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de Entrenamiento\n",
    "\n",
    "Supongamos que tenemos los siguientes datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "    ('chinese beijing chinese', 'zh'),\n",
    "    ('chinese chinese shangai', 'zh'),\n",
    "    ('chinese macao', 'zh'),\n",
    "    ('tokyo japan chinese', 'ja'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc for doc, _ in training]\n",
    "y_train = [cls for _, cls in training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['zh', 'ja']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['chinese', 'beijing', 'shangai', 'macao', 'tokyo', 'japan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución a Priori (\"prior\")\n",
    "\n",
    "Calculemos la distribución a priori (probabilidad de cada clase) usando máxima verosimilitud:\n",
    "\n",
    "$$P(Y = y) = \\frac{Count(Y = y)}{\\sum_{y'} Count(Y = y')}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_count = Counter(y_train)\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob = {}\n",
    "for c in classes:\n",
    "    prior_prob[c] = class_count[c] / len(y_train)\n",
    "    \n",
    "    print(f'P({c}) = {prior_prob[c]:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuciones Condicionales\n",
    "\n",
    "Calculemos las distribuciones condicionales, esto es, la probabilidad de cada feature para cada clase.\n",
    "\n",
    "Usaremos máxima verosimilitud y suavizado \"add-one\":\n",
    "\n",
    "$$P(X_i = x|Y = y) = \\frac{Count(X_i = x, Y = y) + 1}{\\sum_{x'} Count(X_i = x', Y = y)+ |V|}$$\n",
    "\n",
    "Primero calculamos los conteos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = {}\n",
    "\n",
    "for doc, cls in training:\n",
    "    tokens = doc.split()  # lista de palabras\n",
    "    for feature in tokens:\n",
    "        if (feature, cls) not in feature_count:\n",
    "            feature_count[feature, cls] = 0\n",
    "        feature_count[feature, cls] = feature_count[feature, cls] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O más cortito con `defaultdict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "feature_count = defaultdict(int)\n",
    "\n",
    "for doc, cls in training:\n",
    "    tokens = doc.split()  # lista de palabras\n",
    "    for feature in tokens:\n",
    "        feature_count[feature, cls] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos las distribuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(features)\n",
    "\n",
    "cond_prob = {}\n",
    "for c in classes:\n",
    "    cond_prob[c] = {}\n",
    "    \n",
    "    count_sum = sum(feature_count[f, c] for f in features)\n",
    "    denom = count_sum + V\n",
    "\n",
    "    for f in features:\n",
    "        num = feature_count[f, c] + 1\n",
    "        cond_prob[c][f] = num / denom\n",
    "\n",
    "        print(f'P({f}|{c}) = {num} / {denom} ~ {cond_prob[c][f]:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción\n",
    "\n",
    "Dado un documento, calculemos su clasificación. Para ello, calcularemos la probabilidad de cada clase, o mejor dicho algo propocional a esos valores (nos ahorramos el denominador $P(X=x)$).\n",
    "\n",
    "$$P(Y=y|X=x) \\propto P(Y=y) \\prod_{i} P(X_i = x_i|Y=y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'chinese chinese chinese tokyo japan'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_prob = prior_prob['zh']\n",
    "for w in doc:\n",
    "    zh_prob = zh_prob * cond_prob['zh'][w]\n",
    "\n",
    "print(f'P(zh|doc) ~ {zh_prob:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_prob = prior_prob['ja']\n",
    "for w in doc:\n",
    "    ja_prob = ja_prob * cond_prob['ja'][w]\n",
    "\n",
    "print(f'P(ja|doc) ~ {ja_prob:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuál es la clasificación?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores probabilísticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_prob / (zh_prob + ja_prob), ja_prob / (zh_prob + ja_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes con Scikit-learn\n",
    "\n",
    "Veamos cómo podemos clasificar documentos en **scikit-learn** usando Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolsas de Palabras (Bag of Words)\n",
    "\n",
    "Representaremos a los documentos de manera vectorial usando bolsas de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos (sin etiquetas) para que el vectorizador asigne una columna a cada feature posible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo se vectorizan los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2  # shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internamente, el vectorizador guarda el mapeo de features a columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vectorizamos un nuevo documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'chinese chinese chinese tokyo japan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qué pasa si vectorizo esto?\n",
    "doc = 'buenos aires'\n",
    "X_test = vect.transform([doc])\n",
    "X_test.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "Instanciamos y entrenamos [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora predecimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener las probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros Internos\n",
    "\n",
    "Veamos cómo es internamente el modelo Naive Bayes en scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mnb.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(mnb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Aplicar Naive Bayes al problema de reconocimiento de dígitos manuscritos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [Naive Bayes classifier (Wikipedia)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "\n",
    "Python:\n",
    "- [defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict)\n",
    "\n",
    "Scikit-learn:\n",
    "- [Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "- [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "- [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
